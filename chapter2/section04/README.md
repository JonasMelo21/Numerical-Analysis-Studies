# Error Analysis for Iterative Methods

This section explores how to evaluate the **order of convergence** of an iterative method. But what exactly is the **order of convergence**?

## Order of Convergence

The **order of convergence** measures how quickly a method converges to the actual root. Given a method that produces the sequence \( \{p_n\}_{n=0}^\infty \), such that:

\[
p_{n+1} = g(p_n),
\]

we define the order of convergence \( A \) and the asymptotic error \( B \) as:

\[
\lim_{n \to \infty} \frac{|p_{n+1} - p|}{|p_n - p|^A} = B,
\]

where:
- \( p \) is the root,
- \( A \) (order of convergence) determines how fast the method converges,
- \( B \) is the asymptotic error constant.

The higher the value of \( A \), the faster the method converges to \( p \). 

## Examples of Convergence

### Bisection Method
The **Bisection Method** has **linear convergence** (\( A = 1 \)). It is one of the slowest iterative methods.

### Newton's Method
The **Newton Method** can achieve **quadratic convergence** (\( A = 2 \)) under the following conditions:
1. \( f(p) = 0 \),
2. \( f'(p) \neq 0 \),
3. The initial approximation \( p_0 \) lies within an interval \( [p - K, p + K] \), where \( K > 0 \).

### Modified Newton Method
The **Modified Newton Method** is an alternative to Newton's Method for functions with multiple roots. It effectively applies Newton's Method to itself.

For instance, let the sequence generated by the Newton Method be:

\[
N(p_n) = p_{n-1} - \frac{f(p_{n-1})}{f'(p_{n-1})},
\]

where \( N(p_n) \) represents the \( n \)-th term and \( f(x) \) is the function whose root we aim to find.

The **Modified Newton Method** generates its sequence as:

\[
M(p_{n-1}) = p_{n-1} - \frac{N(p_{n-1})}{N'(p_{n-1})},
\]

which simplifies to:

\[
M(p_{n-1}) = \frac{f(p_{n-1}) \cdot f'(p_{n-1})}{\left[f'(p_{n-1})\right]^2 - f(p_{n-1}) \cdot f''(p_{n-1})}.
\]

